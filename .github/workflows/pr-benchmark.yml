name: PR Benchmarks

on:
  pull_request:
    branches: [main, dev]
    paths:
      - "crates/**/*.rs"
      - "Cargo.toml"
      - "Cargo.lock"
      - ".github/workflows/pr-benchmark.yml"
      - ".github/benchmark-baselines.json"

permissions:
  contents: read
  pull-requests: write

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  benchmark:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@stable

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-bench-${{ hashFiles('Cargo.toml', 'crates/*/Cargo.toml') }}

      - name: Run integration tests with performance checks
        run: |
          echo "Running integration tests..."
          cargo test --workspace --release 2>&1 | tee test-output.txt

          echo ""
          echo "Performance tests:"
          grep "‚úÖ" test-output.txt || true

      - name: Run CPU benchmarks
        run: |
          echo "Running CPU benchmarks (quick mode)..."
          cargo bench -p realm-compute-cpu --bench gemm -- --quick 2>&1 | tee bench-cpu.txt
          cargo bench -p realm-compute-cpu --bench fused_kernels -- --quick 2>&1 | tee -a bench-cpu.txt

      - name: Run model benchmarks
        run: |
          echo "Running model benchmarks (quick mode)..."
          cargo bench -p realm-models --bench attention -- --quick 2>&1 | tee bench-models.txt

      - name: Check for performance regressions
        id: regression-check
        run: |
          echo "Checking performance against baselines..."
          if [ -f scripts/check-benchmark-regression.sh ]; then
            bash scripts/check-benchmark-regression.sh
          else
            echo "No regression check script found (optional)"
          fi
        continue-on-error: true

      - name: Extract benchmark summary
        if: always()
        run: |
          echo "## üìä Benchmark Results" > benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "Realm inference orchestration performance benchmarks on this PR." >> benchmark-summary.md
          echo "" >> benchmark-summary.md

          if [ -f bench-cpu.txt ]; then
            echo "### CPU Compute Benchmarks" >> benchmark-summary.md
            echo "\`\`\`" >> benchmark-summary.md
            grep -A 2 "time:" bench-cpu.txt | head -20 >> benchmark-summary.md || true
            echo "\`\`\`" >> benchmark-summary.md
            echo "" >> benchmark-summary.md
          fi

          if [ -f bench-models.txt ]; then
            echo "### Model Inference Benchmarks" >> benchmark-summary.md
            echo "\`\`\`" >> benchmark-summary.md
            grep -A 2 "time:" bench-models.txt | head -20 >> benchmark-summary.md || true
            echo "\`\`\`" >> benchmark-summary.md
            echo "" >> benchmark-summary.md
          fi

          if [ -f test-output.txt ]; then
            echo "### Integration Test Performance" >> benchmark-summary.md
            echo "\`\`\`" >> benchmark-summary.md
            grep "‚úÖ.*¬µs\|‚úÖ.*ms" test-output.txt >> benchmark-summary.md || echo "No performance data" >> benchmark-summary.md
            echo "\`\`\`" >> benchmark-summary.md
          fi

          echo "" >> benchmark-summary.md
          echo "---" >> benchmark-summary.md
          echo "*Thresholds defined in [benchmark-baselines.json](.github/benchmark-baselines.json) (if available)*" >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "**Note:** These benchmarks measure orchestration overhead and compute efficiency." >> benchmark-summary.md

      - name: Comment PR with results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('benchmark-summary.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Upload benchmark artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            bench-*.txt
            test-output.txt
            benchmark-summary.md

      - name: Fail if regressions detected
        if: steps.regression-check.outcome == 'failure'
        run: |
          echo "‚ùå Performance regressions detected!"
          echo "Please review the benchmark results above."
          echo ""
          echo "If the regression is expected (e.g., adding features),"
          echo "update the baselines in .github/benchmark-baselines.json"
          exit 1

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-integration-${{ hashFiles('Cargo.toml', 'crates/*/Cargo.toml') }}

      - name: Run core integration tests
        run: |
          echo "Running realm-core integration tests..."
          cargo test -p realm-core --release

      - name: Build orchestration examples
        run: |
          echo "Building inference orchestration examples..."

          echo "Building simple-realm-test..."
          cargo build --release --bin simple-realm-test

          echo "Building multi-tenant..."
          cargo build --release --bin multi-tenant

          echo "Building paris-generation..."
          cargo build --release --bin paris-generation

          echo "‚úÖ All examples built successfully"

      - name: Verify example compilation
        run: |
          echo "Verifying orchestration examples compile correctly..."

          # Verify binaries exist
          if [ -f target/release/simple-realm-test ]; then
            echo "‚úÖ simple-realm-test binary exists"
          else
            echo "‚ùå simple-realm-test binary not found"
            exit 1
          fi

          if [ -f target/release/multi-tenant ]; then
            echo "‚úÖ multi-tenant binary exists"
          else
            echo "‚ùå multi-tenant binary not found"
            exit 1
          fi

          if [ -f target/release/paris-generation ]; then
            echo "‚úÖ paris-generation binary exists"
          else
            echo "‚ùå paris-generation binary not found"
            exit 1
          fi

          echo ""
          echo "Note: Examples require GGUF model files to run."
          echo "Skipping runtime tests (no model files in CI)."

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            *-test.txt
